ðŸŽ§ DeepFake Audio Detection Using MFCC and Pretrained VGG16


This project aims to detect deepfake audio by leveraging MFCC (Mel Frequency Cepstral Coefficients) for extracting relevant features and a pretrained VGG16 deep learning model for classification. The raw audio signals are transformed into spectrogram-like representations using MFCC, which are then input into the pretrained VGG16 model, fine-tuned for audio classification tasks. This approach significantly outperforms traditional machine learning models such as SVM and Gradient Boosting in terms of precision, recall, and accuracy. The system is trained and validated using the Fake or Real (FoR) Audio Dataset, offering a reliable and scalable solution to combat audio-based deepfake threats.
